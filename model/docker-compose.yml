version: "3.9"
services:
  analyzer:
    build: ./analyzer
    ports: ["8000:8000"]
    environment:
      - PYTHONUNBUFFERED=1
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: "2g"

  suggestions:
    build: ./suggestions
    ports: ["8001:8001"]
    environment:
      - HF_API_KEY=${HF_API_KEY}
      - HF_API_URL=https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-3B-Instruct
    depends_on: [analyzer]
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: "1g"
